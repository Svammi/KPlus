{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем первичное сравнение файлов на наличие явных изменений в них. Для этого сравним размерность данных \"до\" и \"после\" миграции. Если размерность таблци будет одинаковая, тогда вычислим хем-значение и сравним их \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def is_hash_equals(rows_old, rows_new):\n",
    "    return pd.util.hash_pandas_object(rows_old).sum() == pd.util.hash_pandas_object(rows_new).sum()\n",
    "\n",
    "def is_hash_equals_sorted(rows_old, rows_new):\n",
    "    sorted_data_old = pd.DataFrame(rows_old).sort_values(by='id')\n",
    "    sorted_data_new = pd.DataFrame(rows_new).sort_values(by='id')\n",
    "    return pd.util.hash_pandas_object(sorted_data_old).sum() == pd.util.hash_pandas_object(sorted_data_new).sum()\n",
    "\n",
    "data_users_old = pd.read_csv('old_DB/users.csv', delimiter=\";\", encoding=\"cp1251\")\n",
    "data_users_new = pd.read_csv('new_DB/newusers.csv', delimiter=\";\", encoding=\"cp1251\")\n",
    "data_folders_old = pd.read_csv('old_DB/folders.csv', delimiter=\";\", encoding=\"cp1251\")\n",
    "data_folders_new = pd.read_csv('new_DB/newfolders.csv', delimiter=\";\", encoding=\"cp1251\")\n",
    "data_documents_old = pd.read_csv('old_DB/folders_content.csv', delimiter=\";\", encoding=\"cp1251\")\n",
    "data_documents_new = pd.read_csv('new_DB/newfolders_content.csv', delimiter=\";\", encoding=\"cp1251\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   id      6 non-null      int64\n",
      " 1   name    6 non-null      int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 160.0 bytes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   id      6 non-null      int64\n",
      " 1   name    6 non-null      int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 160.0 bytes\n",
      "Совпадают ли таблицы USERS: ДА\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 219 entries, 0 to 218\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      219 non-null    int64 \n",
      " 1   sid     213 non-null    object\n",
      " 2   name    212 non-null    object\n",
      " 3   type    219 non-null    int64 \n",
      " 4   owner   219 non-null    int64 \n",
      " 5   parent  219 non-null    int64 \n",
      " 6   tm      219 non-null    int64 \n",
      "dtypes: int64(5), object(2)\n",
      "memory usage: 10.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 223 entries, 0 to 222\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      223 non-null    int64 \n",
      " 1   sid     217 non-null    object\n",
      " 2   name    216 non-null    object\n",
      " 3   type    223 non-null    int64 \n",
      " 4   owner   223 non-null    int64 \n",
      " 5   parent  223 non-null    int64 \n",
      " 6   tm      223 non-null    int64 \n",
      "dtypes: int64(5), object(2)\n",
      "memory usage: 10.5+ KB\n",
      "Совпадают ли таблицы FOLDERS: НЕТ\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2061 entries, 0 to 2060\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        2061 non-null   int64 \n",
      " 1   objid     2061 non-null   int64 \n",
      " 2   docn      2061 non-null   int64 \n",
      " 3   basename  2060 non-null   object\n",
      " 4   dtmod     2061 non-null   int64 \n",
      " 5   sliceid   2060 non-null   object\n",
      " 6   family    2061 non-null   int64 \n",
      "dtypes: int64(5), object(2)\n",
      "memory usage: 96.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2151 entries, 0 to 2150\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           2151 non-null   int64  \n",
      " 1   objid        2151 non-null   int64  \n",
      " 2   docn         2151 non-null   int64  \n",
      " 3   basename     2134 non-null   object \n",
      " 4   dtmod        2151 non-null   int64  \n",
      " 5   sliceid      2134 non-null   object \n",
      " 6   family       2151 non-null   int64  \n",
      " 7   Unnamed: 7   0 non-null      float64\n",
      " 8   Unnamed: 8   0 non-null      float64\n",
      " 9   Unnamed: 9   0 non-null      float64\n",
      " 10  Unnamed: 10  0 non-null      float64\n",
      " 11  Unnamed: 11  0 non-null      float64\n",
      " 12  Unnamed: 12  0 non-null      float64\n",
      "dtypes: float64(6), int64(5), object(2)\n",
      "memory usage: 201.7+ KB\n",
      "Совпадают ли таблицы FOLDERS_CONTENT: НЕТ\n"
     ]
    }
   ],
   "source": [
    "data_users_old.info()\n",
    "data_users_new.info()\n",
    "print(\"Совпадают ли таблицы USERS: \" + (\"ДА\" if is_hash_equals(data_users_old, data_users_new) else \"НЕТ\" ))\n",
    "\n",
    "data_folders_old.info()\n",
    "data_folders_new.info()\n",
    "print(\"Совпадают ли таблицы FOLDERS: \" + (\"ДА\" if is_hash_equals(data_folders_old, data_folders_new) else \"НЕТ\" ))\n",
    "\n",
    "data_documents_old.info()\n",
    "data_documents_new.info()\n",
    "print(\"Совпадают ли таблицы FOLDERS_CONTENT: \" + (\"ДА\" if is_hash_equals(data_documents_old, data_documents_new) else \"НЕТ\" ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После сравнения данных, имеем следующие результаты:\n",
    "- таблица Users при миграции сохранила все свои значения и размерность\n",
    "- размерность таблицы Folders после миграции отличается, количество записей в новой таблице увеличилось\n",
    "- размерность таблицы Folders_content после миграции также отличается, в новой таблице увеличилось количестов записей.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Для дальнейшего исследования на целостность мы не будем рассматривать таблицы Users,т.к. они абсолютно одинаковые. Поскольку перенос записей для таблиц Folders и Folders_content нарушился, наqдем симметричную разность id записей для каждой из них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Найдем id записей, которые не перенеслись со старой таблицы Folders\n",
      "3\n",
      " Найдем id записей, которых не было в старой таблице Folders, но после миграции появились в новой\n",
      "7\n",
      " Найдем id записей, которые не перенеслись со старой таблицы Folders_contents\n",
      "323\n",
      " Найдем id записей, которых не было в старой таблице Folders_contents, но после миграции появились в новой\n",
      "413\n"
     ]
    }
   ],
   "source": [
    "print(' Найдем id записей, которые не перенеслись со старой таблицы Folders')\n",
    "is_not_id_in_folders_new = list(set(data_folders_old['id']) - set(data_folders_new['id']))\n",
    "print(len(is_not_id_in_folders_new))\n",
    "print(' Найдем id записей, которых не было в старой таблице Folders, но после миграции появились в новой')\n",
    "is_not_id_in_folders_old = list(set(data_folders_new['id']) - set(data_folders_old['id']))\n",
    "print(len(is_not_id_in_folders_old))\n",
    "print(' Найдем id записей, которые не перенеслись со старой таблицы Folders_contents')\n",
    "is_not_id_in_documents_new = list(set(data_documents_old['id']) - set(data_documents_new['id']))\n",
    "print(len(is_not_id_in_documents_new))\n",
    "print(' Найдем id записей, которых не было в старой таблице Folders_contents, но после миграции появились в новой')\n",
    "is_not_id_in_documents_old = list(set(data_documents_new['id']) - set(data_documents_old['id']))\n",
    "print(len(is_not_id_in_documents_old))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из полученных значений, можно сделать следующие выводы:\n",
    "- не все записи из старых таблиц были перенесены в новые, а именно утеряны 3 записи из таблицы Folders, 323 записей из таблицы Folders_contents\n",
    "- в новых таблицах нашлись новые записи, которых ранее не было сохранено в старых таблицах, а именно найдено 7 записей в таблице Folders и 413 записей в таблице Folders_contents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.к. старые таблицы Folders_contents и Folders связаны между собой, проверим принадлежат ли утерянные 323 записей из Folders_contents утерянным записям из таблицы Folders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Из старой таблицы была утеряна часть документов из папок:\n",
      "[ 848854 1324630 1324629 1243404 1271187 1418758 1275677 1398500 1284814\n",
      " 1321803 1269515 1540906 1532406 1257225 1302061 1610881 1537347 1277140\n",
      " 1243371 1537346]\n",
      "Папки из старой таблицы, которые полностью были утеряны:\n",
      "[1610881, 1540906, 1537347]\n",
      "Папки тех документов, которые были найдены в новой таблице и отсутствовали в старой:\n",
      "[1613634 1613635 1243404 1269515 1398500 1324629 1623185 1302061 1625573\n",
      " 1532406 1277140 1321803 1284814 1275677 1271187  848854 1537346 1324630\n",
      " 1629882 1418758 1257225 1621168 1631113 1243371]\n",
      "Папки из новой таблицы, которых не было в старой:\n",
      "[1613634, 1613635, 1625573, 1631113, 1621168, 1623185, 1629882]\n"
     ]
    }
   ],
   "source": [
    "# из новой таблицы Folders_contents получим список \"objid\" для документов, которых не было найдено в старой таблице\n",
    "id_odjid_not_save_documents_new = data_documents_old[data_documents_old.id.isin(is_not_id_in_documents_new)]['objid'].unique()\n",
    "print('Из старой таблицы была утеряна часть документов из папок:')\n",
    "print(id_odjid_not_save_documents_new)\n",
    "print('Папки из старой таблицы, которые полностью были утеряны:')\n",
    "print(is_not_id_in_folders_new)\n",
    "\n",
    "\n",
    "id_odjid_not_save_documents_old = data_documents_new[data_documents_new.id.isin(is_not_id_in_documents_old)]['objid'].unique()\n",
    "print('Папки тех документов, которые были найдены в новой таблице и отсутствовали в старой:')\n",
    "print(id_odjid_not_save_documents_old)\n",
    "print('Папки из новой таблицы, которых не было в старой:')\n",
    "print(is_not_id_in_folders_old)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы имеем, что при миграции БД, часть документов из папок [848854 1324630 1324629 1243404 1271187 1418758 1275677 1398500 1284814\n",
    " 1321803 1269515 1540906 1532406 1257225 1302061 1610881 1537347 1277140\n",
    " 1243371 1537346 ] была утеряна, кроме того папки [1610881, 1540906, 1537347] были полностью утеряны с вложенными данными.\n",
    " В новой БД нашлись новые папки [1613634, 1613635, 1625573, 1631113, 1621168, 1623185, 1629882] и новые документы, которые связаны как со старыми папками так и с новыми. Возможно, до моменты выгрузки и начала исследования данных, пользователями были созданы новые папки и файлы, что объясняло бы увеличение размерности новой БД и появление новых записей. Но отсутствие даты создания записи не позволяет проверить данную гипотезу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим какая часть данных из каждой папки была утеряна."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1537346: 60, 1243404: 50, 1269515: 34, 848854: 28, 1537347: 26, 1257225: 22, 1271187: 19, 1275677: 14, 1321803: 12, 1302061: 12, 1277140: 9, 1324629: 7, 1398500: 7, 1284814: 7, 1532406: 6, 1324630: 3, 1540906: 3, 1243371: 2, 1418758: 1, 1610881: 1})\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "folders = data_documents_old[data_documents_old.id.isin(is_not_id_in_documents_new)]['objid']\n",
    "name_folder_and_count = Counter(folders)\n",
    "print(name_folder_and_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы #\n",
    "1. Данные пользователей сохранились  без потерь\n",
    "2. При переносе папок и документов часть файлов была утеряна.\n",
    "3. Новые таблицы с данными о папках и документах имееют большую размерность. Возможно, это новые записи, которые были внесены после миграции. К сожалению, нет данных о времени и даты сохранения записей, чтобы проверить данную гипотезу.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
